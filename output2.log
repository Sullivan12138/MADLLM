Args in experiment:
Namespace(activation='gelu', anomaly_ratio=1.0, batch_size=128, c_out=25, channels=25, checkpoints='./checkpoints/', d_ff=768, d_model=768, data='PSM', data_path='ETTh1.csv', dec_in=7, des='test', devices='0,1,2,3', distil=True, dropout=0.1, embed='timeF', enc_in=25, factor=1, feature_epochs=10, feature_lr=0.001, features='M', freq='h', gpt_layers=6, gpu=0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, ln=0, loss='MSE', lradj='type1', mask_rate=0.25, mlp=0, model='GPT4TS', model_id='PSM', moving_avg=25, nb_random_samples=10, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patch_size=1, patience=3, percent=5, pool_size=10, pred_len=0, prompt_len=5, resume=False, root_path='./all_datasets/PSM', seasonal_patterns='Monthly', seq_len=100, stride=1, target='OT', top_k=5, train_epochs=10, use_amp=False, use_feature_embedding=True, use_gpu=True, use_multi_gpu=False, use_prompt_pool=True, use_skip_embedding=True, visualize=False, weight=0)
Use GPU: cuda:0
>>>>>>>start training : PSM_GPT4TS_PSM_sl100_dm768_df768_0_seTrue_feTrue_ppTrue_top5_pl5_ps10_nrs10_flr0.001_fepo10_ch25_reFalse>>>>>>>>>>>>>>>>>>>>>>>>>>
test: (87841, 25)
train: (132481, 25)
train 132382
test: (87841, 25)
train: (132481, 25)
val 87742
test: (87841, 25)
train: (132481, 25)
test 87742
Start train feature encoder...
Epoch: 0
Save Encoder Model...
Epoch: 1
Save Encoder Model...
Epoch: 2
Save Encoder Model...
Epoch: 3
Epoch: 4
Epoch: 5
	iters: 100, epoch: 1 | loss: 0.0000001
	speed: 0.1711s/iter; left time: 1753.6550s
	iters: 200, epoch: 1 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1716.5382s
	iters: 300, epoch: 1 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 1702.3952s
	iters: 400, epoch: 1 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 1682.1470s
	iters: 500, epoch: 1 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1665.9723s
	iters: 600, epoch: 1 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 1648.1851s
	iters: 700, epoch: 1 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 1631.4190s
	iters: 800, epoch: 1 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 1614.4524s
	iters: 900, epoch: 1 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 1597.5836s
	iters: 1000, epoch: 1 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1580.8257s
Epoch: 1 cost time: 175.22646713256836
Epoch: 1, Steps: 1035 | Train Loss: 0.0000001 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (inf --> 0.000000).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0000000
	speed: 1.0340s/iter; left time: 9529.4878s
	iters: 200, epoch: 2 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 1540.3869s
	iters: 300, epoch: 2 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1524.2450s
	iters: 400, epoch: 2 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1507.2694s
	iters: 500, epoch: 2 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 1492.6919s
	iters: 600, epoch: 2 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 1473.2648s
	iters: 700, epoch: 2 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 1456.1479s
	iters: 800, epoch: 2 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1439.9003s
	iters: 900, epoch: 2 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1423.4372s
	iters: 1000, epoch: 2 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 1405.6406s
Epoch: 2 cost time: 175.18555903434753
Epoch: 2, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.0000000
	speed: 1.0338s/iter; left time: 8457.4286s
	iters: 200, epoch: 3 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1366.4820s
	iters: 300, epoch: 3 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1349.9674s
	iters: 400, epoch: 3 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1332.9227s
	iters: 500, epoch: 3 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1315.8239s
	iters: 600, epoch: 3 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1298.6505s
	iters: 700, epoch: 3 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1282.0781s
	iters: 800, epoch: 3 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 1266.7432s
	iters: 900, epoch: 3 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1248.1097s
	iters: 1000, epoch: 3 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1231.1067s
Epoch: 3 cost time: 175.25181007385254
Epoch: 3, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.0000000
	speed: 1.0343s/iter; left time: 7391.4448s
	iters: 200, epoch: 4 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1191.5155s
	iters: 300, epoch: 4 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1174.3817s
	iters: 400, epoch: 4 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1157.5258s
	iters: 500, epoch: 4 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1140.7827s
	iters: 600, epoch: 4 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1123.7874s
	iters: 700, epoch: 4 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 1107.5285s
	iters: 800, epoch: 4 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1089.9131s
	iters: 900, epoch: 4 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 1073.1629s
	iters: 1000, epoch: 4 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 1057.5948s
Epoch: 4 cost time: 175.23288249969482
Epoch: 4, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.0000000
	speed: 1.0344s/iter; left time: 6321.1581s
	iters: 200, epoch: 5 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 1016.8080s
	iters: 300, epoch: 5 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 999.9646s
	iters: 400, epoch: 5 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 983.1558s
	iters: 500, epoch: 5 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 966.0843s
	iters: 600, epoch: 5 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 948.9507s
	iters: 700, epoch: 5 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 931.8637s
	iters: 800, epoch: 5 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 915.1846s
	iters: 900, epoch: 5 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 898.2565s
	iters: 1000, epoch: 5 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 881.1036s
Epoch: 5 cost time: 175.2641897201538
Epoch: 5, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.0000000
	speed: 1.0335s/iter; left time: 5245.8829s
	iters: 200, epoch: 6 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 840.8354s
	iters: 300, epoch: 6 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 824.6284s
	iters: 400, epoch: 6 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 807.6900s
	iters: 500, epoch: 6 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 790.6465s
	iters: 600, epoch: 6 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 773.8135s
	iters: 700, epoch: 6 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 756.8161s
	iters: 800, epoch: 6 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 740.1354s
	iters: 900, epoch: 6 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 723.1794s
	iters: 1000, epoch: 6 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 706.1947s
Epoch: 6 cost time: 175.233473777771
Epoch: 6, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.0000000
	speed: 1.0346s/iter; left time: 4180.9285s
	iters: 200, epoch: 7 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 666.4183s
	iters: 300, epoch: 7 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 650.6263s
	iters: 400, epoch: 7 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 632.5691s
	iters: 500, epoch: 7 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 616.1060s
	iters: 600, epoch: 7 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 599.0683s
	iters: 700, epoch: 7 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 582.0174s
	iters: 800, epoch: 7 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 565.5428s
	iters: 900, epoch: 7 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 548.5642s
	iters: 1000, epoch: 7 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 531.3222s
Epoch: 7 cost time: 175.33240628242493
Epoch: 7, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.0000000
	speed: 1.0344s/iter; left time: 3109.2704s
	iters: 200, epoch: 8 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 491.6522s
	iters: 300, epoch: 8 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 474.4482s
	iters: 400, epoch: 8 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 457.6585s
	iters: 500, epoch: 8 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 441.2323s
	iters: 600, epoch: 8 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 423.7059s
	iters: 700, epoch: 8 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 406.7040s
	iters: 800, epoch: 8 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 389.8138s
	iters: 900, epoch: 8 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 372.9431s
	iters: 1000, epoch: 8 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 356.0406s
Epoch: 8 cost time: 175.25712418556213
Epoch: 8, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.0000000
	speed: 1.0349s/iter; left time: 2039.7101s
	iters: 200, epoch: 9 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 316.4751s
	iters: 300, epoch: 9 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 299.5260s
	iters: 400, epoch: 9 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 282.6061s
	iters: 500, epoch: 9 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 265.6391s
	iters: 600, epoch: 9 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 248.7985s
	iters: 700, epoch: 9 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 232.2019s
	iters: 800, epoch: 9 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 215.0383s
	iters: 900, epoch: 9 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 198.0384s
	iters: 1000, epoch: 9 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 181.1358s
Epoch: 9 cost time: 175.29418659210205
Epoch: 9, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.0000000
	speed: 1.0339s/iter; left time: 967.7427s
	iters: 200, epoch: 10 | loss: 0.0000000
	speed: 0.1691s/iter; left time: 141.3487s
	iters: 300, epoch: 10 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 124.4020s
	iters: 400, epoch: 10 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 107.4994s
	iters: 500, epoch: 10 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 90.6077s
	iters: 600, epoch: 10 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 73.7021s
	iters: 700, epoch: 10 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 56.7981s
	iters: 800, epoch: 10 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 39.8844s
	iters: 900, epoch: 10 | loss: 0.0000000
	speed: 0.1690s/iter; left time: 22.9862s
	iters: 1000, epoch: 10 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 6.0947s
Epoch: 10 cost time: 175.1874327659607
Epoch: 10, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : PSM_GPT4TS_PSM_sl100_dm768_df768_0_seTrue_feTrue_ppTrue_top5_pl5_ps10_nrs10_flr0.001_fepo10_ch25_reFalse<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test: (87841, 25)
train: (132481, 25)
test 87742
test: (87841, 25)
train: (132481, 25)
train 132382
Threshold : 1.5389418255296135e-08
pred:    (8774200,)
gt:      (8774200,)
pred:  (8774200,)
gt:    (8774200,)
Accuracy : 0.9353, Precision : 0.9470, Recall : 0.8123, F-score : 0.8745, AUC : 0.8974
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=1.0, batch_size=128, c_out=25, channels=25, checkpoints='./checkpoints/', d_ff=768, d_model=768, data='PSM', data_path='ETTh1.csv', dec_in=7, des='test', devices='0,1,2,3', distil=True, dropout=0.1, embed='timeF', enc_in=25, factor=1, feature_epochs=10, feature_lr=0.001, features='M', freq='h', gpt_layers=6, gpu=0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, ln=0, loss='MSE', lradj='type1', mask_rate=0.25, mlp=0, model='GPT4TS', model_id='PSM', moving_avg=25, nb_random_samples=15, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patch_size=1, patience=3, percent=5, pool_size=10, pred_len=0, prompt_len=5, resume=False, root_path='./all_datasets/PSM', seasonal_patterns='Monthly', seq_len=100, stride=1, target='OT', top_k=5, train_epochs=10, use_amp=False, use_feature_embedding=True, use_gpu=True, use_multi_gpu=False, use_prompt_pool=True, use_skip_embedding=True, visualize=False, weight=0)
Use GPU: cuda:0
>>>>>>>start training : PSM_GPT4TS_PSM_sl100_dm768_df768_0_seTrue_feTrue_ppTrue_top5_pl5_ps10_nrs15_flr0.001_fepo10_ch25_reFalse>>>>>>>>>>>>>>>>>>>>>>>>>>
test: (87841, 25)
train: (132481, 25)
train 132382
test: (87841, 25)
train: (132481, 25)
val 87742
test: (87841, 25)
train: (132481, 25)
test 87742
Start train feature encoder...
Epoch: 0
Save Encoder Model...
Epoch: 1
Save Encoder Model...
Epoch: 2
Epoch: 3
Save Encoder Model...
Epoch: 4
Save Encoder Model...
Epoch: 5
Epoch: 6
Epoch: 7
Save Encoder Model...
Epoch: 8
Save Encoder Model...
Epoch: 9
Save Encoder Model...
	iters: 100, epoch: 1 | loss: 0.0000001
	speed: 0.1716s/iter; left time: 1759.4698s
	iters: 200, epoch: 1 | loss: 0.0000000
	speed: 0.1695s/iter; left time: 1721.0487s
	iters: 300, epoch: 1 | loss: 0.0000000
	speed: 0.1698s/iter; left time: 1707.0617s
	iters: 400, epoch: 1 | loss: 0.0000000
	speed: 0.1696s/iter; left time: 1687.4513s
	iters: 500, epoch: 1 | loss: 0.0000000
	speed: 0.1695s/iter; left time: 1669.6727s
	iters: 600, epoch: 1 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 1652.2134s
	iters: 700, epoch: 1 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 1633.4312s
	iters: 800, epoch: 1 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 1616.4006s
	iters: 900, epoch: 1 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 1599.5748s
	iters: 1000, epoch: 1 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 1582.4118s
Epoch: 1 cost time: 175.6048514842987
Epoch: 1, Steps: 1035 | Train Loss: 0.0000001 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (inf --> 0.000000).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0000000
	speed: 1.0447s/iter; left time: 9628.0613s
	iters: 200, epoch: 2 | loss: 0.0000000
	speed: 0.1711s/iter; left time: 1560.1567s
	iters: 300, epoch: 2 | loss: 0.0000000
	speed: 0.1714s/iter; left time: 1545.7411s
	iters: 400, epoch: 2 | loss: 0.0000000
	speed: 0.1714s/iter; left time: 1527.8541s
	iters: 500, epoch: 2 | loss: 0.0000000
	speed: 0.1715s/iter; left time: 1511.7222s
	iters: 600, epoch: 2 | loss: 0.0000000
	speed: 0.1716s/iter; left time: 1495.5132s
	iters: 700, epoch: 2 | loss: 0.0000000
	speed: 0.1713s/iter; left time: 1475.9555s
	iters: 800, epoch: 2 | loss: 0.0000000
	speed: 0.1720s/iter; left time: 1465.0795s
	iters: 900, epoch: 2 | loss: 0.0000000
	speed: 0.1699s/iter; left time: 1430.1729s
	iters: 1000, epoch: 2 | loss: 0.0000000
	speed: 0.1698s/iter; left time: 1411.8813s
Epoch: 2 cost time: 177.3435890674591
Epoch: 2, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.0000000
	speed: 1.0348s/iter; left time: 8465.7292s
	iters: 200, epoch: 3 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 1369.1870s
	iters: 300, epoch: 3 | loss: 0.0000000
	speed: 0.1695s/iter; left time: 1352.4158s
	iters: 400, epoch: 3 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 1335.2877s
	iters: 500, epoch: 3 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 1318.4759s
	iters: 600, epoch: 3 | loss: 0.0000000
	speed: 0.1696s/iter; left time: 1302.9807s
	iters: 700, epoch: 3 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 1284.4866s
	iters: 800, epoch: 3 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 1267.2686s
	iters: 900, epoch: 3 | loss: 0.0000000
	speed: 0.1695s/iter; left time: 1250.8767s
	iters: 1000, epoch: 3 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 1233.6974s
Epoch: 3 cost time: 175.59837222099304
Epoch: 3, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.0000000
	speed: 1.0353s/iter; left time: 7398.5327s
	iters: 200, epoch: 4 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 1193.0778s
	iters: 300, epoch: 4 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 1176.2120s
	iters: 400, epoch: 4 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 1159.4224s
	iters: 500, epoch: 4 | loss: 0.0000000
	speed: 0.1695s/iter; left time: 1143.1753s
	iters: 600, epoch: 4 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 1124.9853s
	iters: 700, epoch: 4 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 1108.0225s
	iters: 800, epoch: 4 | loss: 0.0000000
	speed: 0.1695s/iter; left time: 1092.7387s
	iters: 900, epoch: 4 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 1074.3688s
	iters: 1000, epoch: 4 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 1057.2865s
Epoch: 4 cost time: 175.48708963394165
Epoch: 4, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.0000000
	speed: 1.0346s/iter; left time: 6322.2154s
	iters: 200, epoch: 5 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 1018.2438s
	iters: 300, epoch: 5 | loss: 0.0000000
	speed: 0.1696s/iter; left time: 1002.3764s
	iters: 400, epoch: 5 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 984.1190s
	iters: 500, epoch: 5 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 966.5185s
	iters: 600, epoch: 5 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 950.2946s
	iters: 700, epoch: 5 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 933.0099s
	iters: 800, epoch: 5 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 915.9441s
	iters: 900, epoch: 5 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 899.2478s
	iters: 1000, epoch: 5 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 882.6853s
Epoch: 5 cost time: 175.5237205028534
Epoch: 5, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.0000000
	speed: 1.0352s/iter; left time: 5254.7247s
	iters: 200, epoch: 6 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 842.5926s
	iters: 300, epoch: 6 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 825.5679s
	iters: 400, epoch: 6 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 808.5680s
	iters: 500, epoch: 6 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 791.9600s
	iters: 600, epoch: 6 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 774.9350s
	iters: 700, epoch: 6 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 758.2392s
	iters: 800, epoch: 6 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 741.2852s
	iters: 900, epoch: 6 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 724.1389s
	iters: 1000, epoch: 6 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 707.3363s
Epoch: 6 cost time: 175.4989082813263
Epoch: 6, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.0000000
	speed: 1.0348s/iter; left time: 4181.4678s
	iters: 200, epoch: 7 | loss: 0.0000000
	speed: 0.1696s/iter; left time: 668.4111s
	iters: 300, epoch: 7 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 650.5916s
	iters: 400, epoch: 7 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 633.2875s
	iters: 500, epoch: 7 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 616.4048s
	iters: 600, epoch: 7 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 599.4840s
	iters: 700, epoch: 7 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 582.5498s
	iters: 800, epoch: 7 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 565.6178s
	iters: 900, epoch: 7 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 548.7308s
	iters: 1000, epoch: 7 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 531.6761s
Epoch: 7 cost time: 175.4841697216034
Epoch: 7, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.0000000
	speed: 1.0350s/iter; left time: 3111.1297s
	iters: 200, epoch: 8 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 492.0944s
	iters: 300, epoch: 8 | loss: 0.0000000
	speed: 0.1695s/iter; left time: 475.6779s
	iters: 400, epoch: 8 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 458.1368s
	iters: 500, epoch: 8 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 441.1477s
	iters: 600, epoch: 8 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 424.2285s
	iters: 700, epoch: 8 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 407.3337s
	iters: 800, epoch: 8 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 390.3666s
	iters: 900, epoch: 8 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 373.5301s
	iters: 1000, epoch: 8 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 356.4349s
Epoch: 8 cost time: 175.47537517547607
Epoch: 8, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.0000000
	speed: 1.0348s/iter; left time: 2039.6196s
	iters: 200, epoch: 9 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 316.8676s
	iters: 300, epoch: 9 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 299.8379s
	iters: 400, epoch: 9 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 282.9644s
	iters: 500, epoch: 9 | loss: 0.0000000
	speed: 0.1696s/iter; left time: 266.3932s
	iters: 600, epoch: 9 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 249.1339s
	iters: 700, epoch: 9 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 232.1798s
	iters: 800, epoch: 9 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 215.2317s
	iters: 900, epoch: 9 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 198.2576s
	iters: 1000, epoch: 9 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 181.3869s
Epoch: 9 cost time: 175.52410793304443
Epoch: 9, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.0000000
	speed: 1.0354s/iter; left time: 969.1425s
	iters: 200, epoch: 10 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 141.6221s
	iters: 300, epoch: 10 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 124.6349s
	iters: 400, epoch: 10 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 107.6866s
	iters: 500, epoch: 10 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 90.7602s
	iters: 600, epoch: 10 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 73.8091s
	iters: 700, epoch: 10 | loss: 0.0000000
	speed: 0.1692s/iter; left time: 56.8671s
	iters: 800, epoch: 10 | loss: 0.0000000
	speed: 0.1695s/iter; left time: 40.0022s
	iters: 900, epoch: 10 | loss: 0.0000000
	speed: 0.1693s/iter; left time: 23.0243s
	iters: 1000, epoch: 10 | loss: 0.0000000
	speed: 0.1694s/iter; left time: 6.0967s
Epoch: 10 cost time: 175.49037146568298
Epoch: 10, Steps: 1035 | Train Loss: 0.0000000 Vali Loss: 0.0000000 Test Loss: 0.0000000
Validation loss decreased (0.000000 --> 0.000000).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : PSM_GPT4TS_PSM_sl100_dm768_df768_0_seTrue_feTrue_ppTrue_top5_pl5_ps10_nrs15_flr0.001_fepo10_ch25_reFalse<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test: (87841, 25)
train: (132481, 25)
test 87742
test: (87841, 25)
train: (132481, 25)
train 132382
Threshold : 1.2447310000496284e-08
pred:    (8774200,)
gt:      (8774200,)
pred:  (8774200,)
gt:    (8774200,)
Accuracy : 0.9569, Precision : 0.9612, Recall : 0.8802, F-score : 0.9189, AUC : 0.9333
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=1.0, batch_size=128, c_out=25, channels=25, checkpoints='./checkpoints/', d_ff=768, d_model=768, data='PSM', data_path='ETTh1.csv', dec_in=7, des='test', devices='0,1,2,3', distil=True, dropout=0.1, embed='timeF', enc_in=25, factor=1, feature_epochs=10, feature_lr=0.001, features='M', freq='h', gpt_layers=6, gpu=0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, ln=0, loss='MSE', lradj='type1', mask_rate=0.25, mlp=0, model='GPT4TS', model_id='PSM', moving_avg=25, nb_random_samples=10, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patch_size=1, patience=3, percent=5, pool_size=10, pred_len=0, prompt_len=5, resume=False, root_path='./all_datasets/PSM', seasonal_patterns='Monthly', seq_len=100, stride=1, target='OT', top_k=5, train_epochs=10, use_amp=False, use_feature_embedding=True, use_gpu=True, use_multi_gpu=False, use_prompt_pool=True, use_skip_embedding=True, visualize=False, weight=0)
Use GPU: cuda:0
>>>>>>>start training : PSM_GPT4TS_PSM_sl100_dm768_df768_0_seTrue_feTrue_ppTrue_top5_pl5_ps10_nrs10_flr0.001_fepo10_ch25_reFalse>>>>>>>>>>>>>>>>>>>>>>>>>>
test: (87841, 25)
train: (132481, 25)
train 132382
test: (87841, 25)
train: (132481, 25)
val 87742
test: (87841, 25)
train: (132481, 25)
test 87742
Start train feature encoder...
Epoch: 0
scripts/PSM.sh：行 30: 531325 已杀死               python -u run.py --is_training 1 --root_path ./all_datasets/PSM --model_id PSM --model GPT4TS --data PSM --features M --seq_len 100 --pred_len 0 --gpt_layer 6 --d_model 768 --d_ff 768 --patch_size 1 --stride 1 --enc_in 25 --c_out 25 --anomaly_ratio 1 --batch_size 128 --learning_rate 0.0001 --train_epochs 10 --use_feature_embedding True --use_prompt_pool True --use_skip_embedding True --channels 25 --top_k 5 --prompt_len 5 --pool_size 10 --feature_epochs 10 --feature_lr 0.001 --nb_random_samples 10
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=1.0, batch_size=128, c_out=25, channels=25, checkpoints='./checkpoints/', d_ff=768, d_model=768, data='PSM', data_path='ETTh1.csv', dec_in=7, des='test', devices='0,1,2,3', distil=True, dropout=0.1, embed='timeF', enc_in=25, factor=1, feature_epochs=10, feature_lr=0.001, features='M', freq='h', gpt_layers=6, gpu=0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, ln=0, loss='MSE', lradj='type1', mask_rate=0.25, mlp=0, model='GPT4TS', model_id='PSM', moving_avg=25, nb_random_samples=15, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patch_size=1, patience=3, percent=5, pool_size=10, pred_len=0, prompt_len=5, resume=False, root_path='./all_datasets/PSM', seasonal_patterns='Monthly', seq_len=100, stride=1, target='OT', top_k=5, train_epochs=10, use_amp=False, use_feature_embedding=True, use_gpu=True, use_multi_gpu=False, use_prompt_pool=True, use_skip_embedding=True, visualize=False, weight=0)
Use GPU: cuda:0
>>>>>>>start training : PSM_GPT4TS_PSM_sl100_dm768_df768_0_seTrue_feTrue_ppTrue_top5_pl5_ps10_nrs15_flr0.001_fepo10_ch25_reFalse>>>>>>>>>>>>>>>>>>>>>>>>>>
test: (87841, 25)
train: (132481, 25)
train 132382
test: (87841, 25)
train: (132481, 25)
val 87742
test: (87841, 25)
train: (132481, 25)
test 87742
Start train feature encoder...
Epoch: 0
Traceback (most recent call last):
  File "run.py", line 224, in <module>
    exp.train(setting)
  File "/root/taowei/Project/LLM/MADLLM/exp/exp_anomaly_detection.py", line 82, in train
    self.feature_encoder.fit(train_loader, setting)
  File "/root/taowei/Project/LLM/MADLLM/models/FeatureEncoder.py", line 76, in fit
    loss = self.loss(
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/taowei/Project/LLM/MADLLM/models/layers/triple_loss.py", line 75, in forward
    negative_representation = encoder(input)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/taowei/Project/LLM/MADLLM/models/layers/casual_cnn.py", line 210, in forward
    x = self.causal_cnn(x)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/taowei/Project/LLM/MADLLM/models/layers/casual_cnn.py", line 177, in forward
    return self.network(x)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/taowei/Project/LLM/MADLLM/models/layers/casual_cnn.py", line 132, in forward
    out_causal = self.causal(x)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 259, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 390.00 MiB (GPU 0; 23.64 GiB total capacity; 8.36 GiB already allocated; 147.88 MiB free; 8.40 GiB reserved in total by PyTorch)
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=1.0, batch_size=128, c_out=25, channels=25, checkpoints='./checkpoints/', d_ff=768, d_model=768, data='PSM', data_path='ETTh1.csv', dec_in=7, des='test', devices='0,1,2,3', distil=True, dropout=0.1, embed='timeF', enc_in=25, factor=1, feature_epochs=10, feature_lr=0.001, features='M', freq='h', gpt_layers=6, gpu=0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, ln=0, loss='MSE', lradj='type1', mask_rate=0.25, mlp=0, model='GPT4TS', model_id='PSM', moving_avg=25, nb_random_samples=10, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patch_size=1, patience=3, percent=5, pool_size=10, pred_len=0, prompt_len=5, resume=False, root_path='./all_datasets/PSM', seasonal_patterns='Monthly', seq_len=100, stride=1, target='OT', top_k=5, train_epochs=10, use_amp=False, use_feature_embedding=True, use_gpu=True, use_multi_gpu=False, use_prompt_pool=True, use_skip_embedding=True, visualize=False, weight=0)
Use GPU: cuda:0
Traceback (most recent call last):
  File "run.py", line 222, in <module>
    exp = Exp(args)  # set experiments
  File "/root/taowei/Project/LLM/MADLLM/exp/exp_anomaly_detection.py", line 25, in __init__
    super(Exp_Anomaly_Detection, self).__init__(args)
  File "/root/taowei/Project/LLM/MADLLM/exp/exp_basic.py", line 28, in __init__
    self.model, self.feature_encoder = self._build_model()
  File "/root/taowei/Project/LLM/MADLLM/exp/exp_anomaly_detection.py", line 28, in _build_model
    model = self.model_dict[self.args.model].Model(self.args).float()
  File "/root/taowei/Project/LLM/MADLLM/models/GPT4TS.py", line 69, in __init__
    self.gpt2.to(device=device)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/transformers/modeling_utils.py", line 1902, in to
    return super().to(*args, **kwargs)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/module.py", line 673, in to
    return self._apply(convert)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/module.py", line 409, in _apply
    param_applied = fn(param)
  File "/root/Downloads/yes/envs/onefits/lib/python3.8/site-packages/torch/nn/modules/module.py", line 671, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=1.0, batch_size=128, c_out=25, channels=25, checkpoints='./checkpoints/', d_ff=768, d_model=768, data='PSM', data_path='ETTh1.csv', dec_in=7, des='test', devices='0,1,2,3', distil=True, dropout=0.1, embed='timeF', enc_in=25, factor=1, feature_epochs=10, feature_lr=0.001, features='M', freq='h', gpt_layers=6, gpu=0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, ln=0, loss='MSE', lradj='type1', mask_rate=0.25, mlp=0, model='GPT4TS', model_id='PSM', moving_avg=25, nb_random_samples=15, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patch_size=1, patience=3, percent=5, pool_size=10, pred_len=0, prompt_len=5, resume=False, root_path='./all_datasets/PSM', seasonal_patterns='Monthly', seq_len=100, stride=1, target='OT', top_k=5, train_epochs=10, use_amp=False, use_feature_embedding=True, use_gpu=True, use_multi_gpu=False, use_prompt_pool=True, use_skip_embedding=True, visualize=False, weight=0)
Use GPU: cuda:0
>>>>>>>start training : PSM_GPT4TS_PSM_sl100_dm768_df768_0_seTrue_feTrue_ppTrue_top5_pl5_ps10_nrs15_flr0.001_fepo10_ch25_reFalse>>>>>>>>>>>>>>>>>>>>>>>>>>
test: (87841, 25)
train: (132481, 25)
train 132382
test: (87841, 25)
train: (132481, 25)
val 87742
test: (87841, 25)
train: (132481, 25)
test 87742
Start train feature encoder...
Epoch: 0
test.sh：行 14: 532535 已杀死               bash scripts/PSM2.sh
